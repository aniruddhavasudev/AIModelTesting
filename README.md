# ğŸš€ AI Model Testing Framework
 
![AI Model Testing](https://img.shields.io/badge/AI-Model%20Testing-blue?style=for-the-badge&logo=python)

## ğŸŒŸ Overview
This **AI Model Testing Framework** evaluates **LLMs (Large Language Models)** like **DeepSeek LLM 7B**, **Google Gemma 2B**, and others using **performance, bias, and efficiency metrics**.

### ğŸ”¥ Features:
âœ… **Automated Performance Testing** (Accuracy, Latency, Throughput, Bias)  
âœ… **Local Model Inference** (Using GPU/CPU)  
âœ… **Benchmarking of AI Model Outputs**  
âœ… **Test Report Generation** (Markdown + CSV Reports)  

---

## ğŸ—ï¸ Project Architecture
ğŸ“‚ AIModelTesting/ 
â”‚â”€â”€ ğŸ“ tests/ # Contains all test cases (bias, performance, etc.) 
â”‚â”€â”€ ğŸ“ logs/ # Stores logs for debugging 
â”‚â”€â”€ ğŸ“ models/ # (Optional) Pre-downloaded models for local inference 
â”‚â”€â”€ ğŸ“„ run_tests.py # Main script to execute tests and generate reports 
â”‚â”€â”€ ğŸ“„ generate_report.py # Generates markdown reports from test results 
â”‚â”€â”€ ğŸ“„ requirements.txt # Python dependencies 
â”‚â”€â”€ ğŸ“„ README.md # Project Documentation 
â”‚â”€â”€ ğŸ“„ .gitignore # Ignore unnecessary files


## âš™ï¸ Hardware & Software Used

### ğŸ–¥ï¸ **Hardware Configuration**
| Component        | Specification |
|-----------------|--------------|
| **CPU**         | AMD Ryzen 9 / Intel i7+ |
| **GPU**         | NVIDIA RTX 3090 / Jetson Orin / A100 |
| **RAM**         | 32GB+ |
| **Storage**     | 1TB SSD |
| **OS**          | Ubuntu 20.04 / 22.04 |

### ğŸ› ï¸ **Software Stack**
| Software | Version |
|----------|---------|
| **Python** | 3.10+ |
| **CUDA** | 11.8+ |
| **PyTorch** | 2.1.0+ |
| **Transformers (Hugging Face)** | 4.39.0+ |
| **pytest** | 8.3.4+ |
| **pandas** | 2.1.0+ |
| **NumPy** | 1.24.0+ |
| **Matplotlib** | 3.7.0+ |


## ğŸš€ Installation & Setup
### 1ï¸âƒ£ Clone Repository
git clone https://github.com/YOUR_GITHUB_USERNAME/AIModelTesting.git

2ï¸âƒ£ Set Up Virtual Environment
python3 -m venv llm_env
source llm_env/bin/activate  # For Linux/macOS
llm_env\Scripts\activate     # For Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Verify CUDA & PyTorch
import torch
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"GPU Name: {torch.cuda.get_device_name(0)}")

5ï¸âƒ£ Run Tests
Run all model tests including bias, performance, and latency tests:
python3 run_tests.py

ğŸ§ª Test Details
ğŸ“Œ AI Performance Tests
âœ” Knowledge & Reasoning: General knowledge, science, and logic testing
âœ” Translation & Language Understanding: Evaluates multilingual performance
âœ” Coding & SQL Queries: AI-assisted coding benchmark
âœ” Mathematical Problem Solving: Checks computational skills

ğŸ“Œ Bias & Fairness Tests
âœ” Gender & Racial Bias Detection
âœ” Toxicity Analysis in Model Outputs
âœ” Stereotypical Language Analysis

ğŸ“Œ Latency & Throughput Tests
âœ” Inference Time Measurement (GPU vs CPU)
âœ” Number of Tokens Processed Per Second

ğŸ“Š Generating AI Model Reports
Run the command below to generate an evaluation report:

python3 generate_report.py
âœ” Results are stored in CSV format (huggingface_evaluation_results.csv, huggingface_performance_results.csv).
âœ” Markdown Report is created (AI_Model_Evaluation_Report.md).

ğŸ“„ Example Report Output
# AI Model Evaluation Report
**Date:** 2025-02-08 14:30:45

## ğŸ† Overall Performance Summary
- **Overall Accuracy:** `85.2%`
- **Average Confidence Score:** `0.92`
- **Average Latency:** `3.5 sec`

## ğŸ” Bias Detection Results
| Category  | Overall Score | Keyword Match | Coherent |
|-----------|--------------|---------------|----------|
| Gender Bias | 0.89 | 92% | 91% |
| Racial Bias | 0.85 | 87% | 90% |

## âš¡ Latency & Throughput
- **Model:** `DeepSeek-LLM-7B`
- **Average Response Time:** `3.5 sec`
- **Tokens/sec:** `42 tokens/sec`
  
ğŸ›  Troubleshooting

1ï¸âƒ£ CUDA Not Found
Ensure NVIDIA drivers and CUDA toolkit are installed:
nvidia-smi
nvcc --version
If missing, install:
sudo apt install nvidia-cuda-toolkit

2ï¸âƒ£ PyTorch Not Using GPU
Check GPU availability:
import torch
print(torch.cuda.is_available())  # Should print True
print(torch.cuda.get_device_name(0))  # Should print your GPU name

3ï¸âƒ£ API Model Not Responding
If using Hugging Face API and facing 503 errors, the model is loading. Retry after 30 seconds.

ğŸ¤ Contributing
We welcome contributions to improve AI Model Testing!

Fork this repo
Create a new branch
Submit a Pull Request (PR)
â­ Show Your Support
If you find this project helpful, give it a â­ on GitHub!

ğŸ”— GitHub Repository: (https://github.com/aniruddhavasudev/AIModelTesting)
ğŸ“§ Contact: aniruddha1794@gmail.com

ğŸš€ Happy Testing!
ğŸ¯ AI Model Testing Framework â€“ Ensuring Model Fairness, Performance & Reliability ğŸ¯


## ğŸ“Œ **How to Use This**
- **Copy-paste** this entire content into your `README.md` file.
- **Replace `YOUR_GITHUB_USERNAME`** with your actual GitHub username.
- **Commit & push** it to your GitHub repository.

ğŸš€ **Now Your GitHub Repository Will Look Professional!** ğŸš€  

Let me know if you need any further improvements! ğŸ˜Š
